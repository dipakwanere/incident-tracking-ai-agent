# Incident Tracking AI Agent

Lightweight incident-tracking AI assistant project.

Overview

This repository contains a minimal agent for tracking and summarizing incidents. The project is prepared for containerized deployment and CI/CD to Render via GitHub Actions.

# AI Incident Triage Agent with RAG + LLM + Observability

This is a lightweight but production-relevant AI Agent for log analysis, incident investigation & RCA (Root Cause Analysis). It mimics real-world AIOps + LLMOps + agentic workflows used in enterprise environments.

Key capabilities:

- Reading multiple log files
- Embedding logs and storing vectors in ChromaDB
- Semantic retrieval (RAG) for log context
- LLM-driven RCA with a fallback prompt on low confidence
- Auto ticket creation via a simulated API
- Observability (latency and agent run logs)
- Easy to extend to LangGraph / CrewAI / AutoGen

ğŸ”¥ Why this project is valuable

**Prompt engineering & tuning:** Multi-stage agent responses with fallback & escalation

**AI Pipeline triaging:** Detects uncertainty â†’ reprocesses â†’ improves answer quality

**Vector DB usage:** Logs indexed as embeddings â†’ semantic retrieval

**AIOps simulation:** Reads system logs, finds issues, classifies failures

**Tool & memory integration:** Store, retrieve, escalate incidents intelligently

**Observability:** Logs execution & latency similar to production AI pipelines

Ideal for interviews and demos for LLMOps, GenAI, MLOps & AIOps roles.

## Architecture

```
				â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
				â”‚ Incident Log Files  â”‚
				â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
						  â†“
			 Chunk + Embed with OpenAI
						  â†“
				 Chroma Vector DB
						  â†“
			   LLM Agent (Primary Prompt)
						  â†“
		If uncertain â†’ Fallback Deep RCA Prompt
						  â†“
		 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Result â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
		 â”‚ Root Cause | Severity | Fix Steps â”‚
		 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
						  â†“
	  Critical? â†’ Auto Create Incident Ticket
						  â†“
		   Observability Logs + Latency Store
```

## Project Structure

```
incident-tracking-ai-agent/
â”‚â”€â”€ main.py
â”‚â”€â”€ api_simulation.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ agent_run_log.txt         (auto-generated)
â”‚â”€â”€ /logs/                    (Add multiple log .txt/.log files here)
â”‚   â”œâ”€â”€ sample1.txt
â”‚   â”œâ”€â”€ sample2.log
â”‚â”€â”€ /vector_store/            (auto-created by Chroma)
â”‚â”€â”€ README.md
```

## Features

- **Semantic log analysis via embeddings:** âœ”
- **Supports multiple log files (.txt/.log):** âœ”
- **Auto RCA generation:** âœ”
- **Critical â†’ auto-creates simulated ticket:** âœ”
- **Self-healing fallback prompt:** âœ”
- **Observability + latency tracking:** âœ”
- **Extendable to LangGraph, CrewAI, AutoGen:** ğŸ”¥

## Getting Started

1. Clone the repository

```powershell
git clone https://github.com/<your-username>/incident-tracking-ai-agent.git
cd incident-tracking-ai-agent
```

2. Create environment & install dependencies

Windows (PowerShell):

```powershell
python -m venv venv
venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install -r requirements.txt
```

Linux / macOS:

```bash
python -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

3. Create a `.env` file in the project root and add your OpenAI API key

```
OPENAI_API_KEY="your_openai_key"
```

4. Add your log files

Place one or more files inside the `logs/` folder. Example:

```
logs/
â”œâ”€â”€ server_cpu_spike.txt
â”œâ”€â”€ kubernetes_restarts.log
â”œâ”€â”€ payment_gateway_timeout.txt
```

5. Run the agent

```powershell
python main.py
```

When prompted, type queries like:

- `What caused CPU spike yesterday?`
- `Why was DB latency high?`
- `Which service is failing repeatedly?`

## Sample Output

```
ğŸ” Final Response:
Root cause: Connection pool exhaustion â†’ DB latency increased â†’ timeout in microservice-A.
Severity: HIGH
Fix: Increase DB pool size, enable autoscaling, add request hedging.

âš  Ticket Created â†’ {'ticket_id': 'INC-7342', 'severity': 'HIGH'}
â± Latency: 1.24 seconds
```

## Troubleshooting

| Issue | Fix |
|---|---|
| API key not found | Check `.env` location or environment variable load |
| No logs detected | Ensure files are inside the `logs/` folder |
| Poor analysis | Add more logs â†’ more embeddings â†’ better context |
| ChromaDB error | Delete `vector_store/` folder â†’ rerun |

## Future Enhancements

You can ask the repo maintainer (or me) to generate code for any of these:

| Feature | Prompt to ask |
|---|---|
| LangGraph multi-agent orchestration | "Upgrade to LangGraph Version" |
| Live log streaming analyzer | "Add real-time log ingestion" |
| Dashboard + metrics visualization | "Add observability dashboard" |
| Severity prediction ML model | "Add severity classifier" |
| API integration with Jira/ServiceNow | "Convert fake API â†’ real API" |

---

If you'd like, I can also:

- Convert imports to the modern `langchain` package API and update `requirements.txt`.
- Add a PowerShell script to bootstrap the environment on Windows.
- Create a no-API offline model variant.

Want me to update `requirements.txt` or commit these changes to git? Say the word.
